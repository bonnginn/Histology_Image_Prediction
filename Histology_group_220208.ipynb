{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21856,"status":"ok","timestamp":1644403846582,"user":{"displayName":"Hironori","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13144149051729585499"},"user_tz":-540},"id":"nrIGleKw-lHX","outputId":"c4e9df8d-cab9-4cb0-e9fd-661014d2e169"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["##自分のgoogle driveをgoogle colaboratoryに接続\n","##実行すると、別windowが開き、googleアカウントへのアクセスを許可するか表示される\n","#\"Mounted at /content/drive\"が表示されれば成功\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Mrxu9UtqrQ8X4-q0pFMKt8fIl2yDxkHG"},"id":"VSsjbQIU-hX2","outputId":"0c6c263e-9a8d-423c-bd3a-caa1948fd471"},"outputs":[],"source":["##Ver 5.0.1 \n","##多グループ対応版\n","##組織学のバーチャルスライドからいろいろな構造（細胞）をとってきて、画像分類するAIをつくるアクティブラーニング用\n","##訓練用画像フォルダの中に、分類ごとにサブフォルダを作成し、その中にjpgまたはpng画像を振り分ける\n","##MobileNet v3から転移学習する。\n","##作成したAIによる推論を行い、正しい分類をしたものに対して、どの程度の正確性があるか？の判定や\n","##画像に対する推論結果を出力することができる。\n","\n","##ライブラリの読み込み\n","\n","import itertools\n","import os\n","import time\n","import re\n","\n","# matplotlib日本語対応バージョン\n","!pip install japanize-matplotlib\n","import matplotlib.pyplot as plt\n","import japanize_matplotlib\n","\n","# 日本語の濁点が分離してしまう問題に対応\n","from unicodedata import normalize\n","\n","import numpy as np\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","from PIL import Image\n","from decimal import Decimal, ROUND_HALF_UP\n","\n","###########################################################################################################\n","#汎用的に使えるようにするためにこの部分に課題ごとに変更が必要になるパラメータを集積する\n","number_of_groups = 4  ##班の数\n","\n","train_data_dir = '/content/drive/MyDrive/group_train' #訓練用画像のフォルダdir\n","\n","test_data_dir = '/content/drive/MyDrive/group_test' #作成したモデルによる推論を行いたい画像フォルダdir\n","Test_images_are_clasified = True #すでに人間が分類したテスト画像に対して推論する場合はTrue、画像に対して推論する場合はFalse\n","\n","save_dir = '/content/drive/MyDrive/result' #最後に出力するjpegファイルを保存するdir\n","\n","model_save = True #モデルを保存する場合はTrue、保存しない場合はFalseにする\n","only_make_model = False #モデルを作成するだけでの場合はTrue、モデルによる推論まで行う場合はFalse\n","\n","##学習にかかわるパラメータ\n","epoch_num = 7 #学習のエポック数\n","#############################################################################################################\n","\n","##計算時間の計測（スタート）\n","start_time = time.time()\n","\n","## NVIDIAのGPUがPCにあれば、設定すればGPUを使って演算させることもできますが、今回の計算量ではGPUは不要です。\n","print(\"TF version:\", tf.__version__)\n","print(\"Hub version:\", hub.__version__)\n","print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")\n","\n","\n","##転移学習に用いる画像分類のモデルの読み込み、設定\n","module_selection = (\"mobilenet_v3_100_224\", 224)\n","handle_base, pixels = module_selection\n","MODULE_HANDLE = \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\".format(handle_base)\n","\n","IMAGE_SIZE = (pixels, pixels)\n","print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n","\n","BATCH_SIZE = 32\n","\n","##グループごとに繰り返す\n","##個人で遊ぶ時にはこの繰り返し構造は不要になるため、学生が自分たちでできるように\n","##するためにはこの繰り返し構造がないファイルを与える。\n","\n","scores =[]\n","\n","#保存フォルダが存在していない場合には作製する\n","if not os.path.exists(save_dir):\n","  os.mkdir(save_dir)\n","\n","for group_no in range(1, number_of_groups + 1):\n","\n","    try:\n","        # data_dir\n","        data_dir = (train_data_dir + '/' + str(group_no))\n","        sample_folders_list = os.listdir(data_dir)\n","        sample_folders = [f for f in sample_folders_list if os.path.isdir(os.path.join(data_dir, f))]\n","\n","        #label情報の保存、フォルダも自動的に作成される\n","        if not os.path.exists(save_dir + '/' + str(group_no) + \"_model\"):\n","            os.mkdir(save_dir + '/' + str(group_no) + \"_model\")\n","        label_txt = open(save_dir + '/' + str(group_no) + '_model/label.txt', 'w', encoding = \"utf-8\")\n","        for class_length in range(len(sample_folders)):\n","            label_txt.write(\"%s\\n\" % sample_folders[class_length])\n","        label_txt.close()\n","\n","        total_sample_number = 0\n","        sample_number_str = \"\"\n","\n","        for o in range(len(sample_folders)):\n","            q = 0\n","            sample_image_files = os.listdir(data_dir + '/' + sample_folders[o])\n","            for p in range(len(sample_image_files)):\n","                patternStr = '.+\\.(jpg|png|PNG|jpeg)'\n","                pattern = re.compile(patternStr)\n","                result = pattern.match(sample_image_files[p])\n","                if result:\n","                    q += 1\n","                    total_sample_number += 1\n","            sample_number_str += normalize(\"NFC\", sample_folders[o]) + \": \" + str(q) + \"  \"\n","\n","        ##ここから先はgoogle colabのものをコピーしてきただけ。\n","        datagen_kwargs = dict(rescale=1. / 255, validation_split=.20)\n","        dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n","                               interpolation=\"bilinear\")\n","\n","        valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","            **datagen_kwargs)\n","        valid_generator = valid_datagen.flow_from_directory(\n","            data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n","\n","        ##augmentation:データの水増し（Trueにすると回転などでデータ数を水増しできる）\n","        do_data_augmentation = False\n","\n","        if do_data_augmentation:\n","            train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","                rotation_range=40,\n","                horizontal_flip=True,\n","                width_shift_range=0.2, height_shift_range=0.2,\n","                shear_range=0.2, zoom_range=0.2,\n","                **datagen_kwargs)\n","        else:\n","            train_datagen = valid_datagen\n","        train_generator = train_datagen.flow_from_directory(\n","            data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)\n","\n","        print(\"Building model with\", MODULE_HANDLE)\n","\n","        # fine tuningの選択（Trueにすると時間はかかるが、Neural network全体のfine tuningが行われる）\n","        do_fine_tuning = False\n","\n","        model = tf.keras.Sequential([\n","            # Explicitly define the input shape so the model can be properly\n","            # loaded by the TFLiteConverter\n","            tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n","            hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n","            tf.keras.layers.Dropout(rate=0.2),\n","            tf.keras.layers.Dense(train_generator.num_classes,\n","                                  kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n","        ])\n","        model.build((None,) + IMAGE_SIZE + (3,))\n","\n","        ##ここで様々なパラメータを変更することもできる（学習効率lrなど）\n","        model.summary()\n","        model.compile(\n","            optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),\n","            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n","            metrics=['accuracy'])\n","        steps_per_epoch = train_generator.samples // train_generator.batch_size\n","        validation_steps = valid_generator.samples // valid_generator.batch_size\n","        hist = model.fit(\n","            train_generator,\n","            epochs=epoch_num, steps_per_epoch=steps_per_epoch,\n","            validation_data=valid_generator,\n","            validation_steps=validation_steps).history\n","    \n","        \n","\n","        # これはここになくてよい気がするので場所の移動を検討\n","        def get_class_string_from_index(index):\n","            for class_string, class_index in valid_generator.class_indices.items():\n","                if class_index == index:\n","                    return class_string\n","                \n","        ##モデルの保存\n","        if model_save:\n","            saved_model_path = save_dir + \"/\" + str(group_no) + \"_model/model\"\n","            tf.keras.models.save_model(model, saved_model_path)\n","        \n","        ##モデルの保存のみで終わる場合\n","        if only_make_model:\n","            if model_save:\n","                print(\"model was saved\")\n","            else:\n","                print(\"If you would like to predict images, you should change 'only_make_model = False'.\")\n","        \n","        ##モデルを使った推論とその出力\n","        else:\n","            ##推論関数\n","            def image_prediction(image_file):\n","                ##推測するために、画像を加工\n","                image_file = image_file.convert(\"RGB\")\n","                image_file= image_file.resize((224, 224))\n","                image_file = np.asarray(image_file)\n","                image_file = image_file.reshape(224, 224, 3)\n","                image_file = image_file / 255\n","                \n","                # Expand the validation image to (1, 224, 224, 3) before predicting the label\n","                prediction_scores = model.predict(np.expand_dims(image_file, axis=0))\n","                predicted_index = np.argmax(prediction_scores)\n","                \n","                return prediction_scores, predicted_index, image_file\n","            \n","            ##分類済みの場合\n","            if Test_images_are_clasified:\n","                folders_list = os.listdir(test_data_dir)\n","                folders = [f for f in folders_list if os.path.isdir(os.path.join(test_data_dir, f))]\n","                \n","                correct = 0\n","                i = 0\n","                image_prediction_list = []\n","                \n","                for l in range(len(folders)):\n","                    image_files = os.listdir(test_data_dir + '/' + folders[l])\n","                    for m in range(len(image_files)):\n","                        patternStr = '.+\\.(jpg|png|PNG|jpeg)'\n","                        pattern = re.compile(patternStr)\n","                        result = pattern.match(image_files[m])\n","                        if result:\n","                            image = Image.open(test_data_dir + '/' + folders[l] + \"/\" + image_files[m])\n","                            image_prediction_list.append([folders[l], image_files[m]])\n","                            prediction_result = image_prediction(image)\n","                            for n in range(3):\n","                                image_prediction_list[i].append(prediction_result[n])\n","                            \n","                            # print(prediction_scores)\n","                            total_score = 0\n","                            predicted_scores = prediction_result[0][0]\n","                            for o in range(len(predicted_scores)):\n","                                if predicted_scores[o] \u003e 0:\n","                                    total_score += predicted_scores[o]\n","                                    predicted_percentage = Decimal(max(predicted_scores) / total_score * 100).quantize(Decimal('0.0'), rounding=ROUND_HALF_UP)\n","                            image_prediction_list[i].append(predicted_percentage)\n","                            \n","                            predicted_label = normalize(\"NFC\", get_class_string_from_index(image_prediction_list[i][3]))\n","                            folder_name = normalize(\"NFC\", folders[l])\n","                            \n","                            image_prediction_list[i].append(predicted_label)\n","                            image_prediction_list[i][0] = folder_name\n","\n","                            if predicted_label == folder_name:\n","                                image_prediction_list[i].append(\"red\")\n","                                correct += 1\n","                            else:\n","                                image_prediction_list[i].append(\"blue\")\n","                            \n","                            i+=1\n","                            \n","         #image_prediction_listは[フォルダ名、画像ファイル名、prediction_score,predicted_index,\n","         #                         image_file, predicted_percentage, predicted_label, output_color]\n","                            \n","                x, y = next(valid_generator) \n","                \n","                # 予測結果を表示させるための図の作成\n","                plt.figure(figsize=(23, 27))\n","                \n","                ##転移学習の結果(lossとaccuracy)をプロット\n","                plt.subplot(4, 4, 1)  # 図を4x4分割した時の1番目に配置するという意味（以下同じ）\n","                plt.ylabel(\"Loss (training and validation)\", fontsize=15)\n","                plt.xlabel(\"Training Steps\", fontsize=15)\n","                plt.ylim([0, 2])\n","                plt.plot(hist[\"loss\"], label=\"training_loss\")\n","                \n","                ##データ数が少なくvalidationできなかった時のエラー回避\n","                try:\n","                    plt.plot(hist[\"val_loss\"], label=\"valuation_loss\")\n","                except:\n","                    print(\"The number of image files were not enough to valuation\")\n","                \n","                plt.legend()\n","                plt.subplot(4, 4, 2)\n","                plt.ylabel(\"Accuracy (training and validation)\", fontsize=15)\n","                plt.xlabel(\"Training Steps\", fontsize=15)\n","                plt.ylim([0, 1])\n","                plt.plot(hist[\"accuracy\"], label=\"training_accuracy\")\n","                ##データ数が少なくvalidationできなかった時のエラー回避\n","                try:\n","                    plt.plot(hist[\"val_accuracy\"], label=\"valuation_accuracy\")\n","                except:\n","                    print(\"\")\n","                plt.legend()\n","                \n","                # 正答率と画像枚数をタイトルとして表示\n","                plt.suptitle(\n","                    \"班番号：\" + str(group_no) + \"\\n正答率 = \" + str(correct) + \"/\" + str(i) + \" (\" + str(\n","                        Decimal(correct / i *100).quantize(Decimal('0.0'), rounding=ROUND_HALF_UP)) + \"%)\"\n","                    + \"\\n画像数（トータル）：\" + str(total_sample_number) + \"\\n\" + sample_number_str,\n","                    fontsize=24)\n","               \n","                for p in range(14):\n","                    if p == i:\n","                        break\n","                    else:\n","                        plt.subplot(4, 4, p + 3)\n","                        plt.imshow(image_prediction_list[p][4])\n","                        plt.axis('off')\n","\n","                        # 画像の上に、教員のアノテーションラベルとAIの予測ラベルを表示\n","                        # アノテーションと予測ラベルが合致する場合、赤色で、間違っている場合は青色で表示する\n","                        # 日本語の濁点が分離してしまう問題にも対応\n","                        plt.title(\n","                            \"Annotated label:\" + image_prediction_list[p][0] + \"\\nPredicted label: \" + image_prediction_list[p][6]\n","                            + \" (\" + str(image_prediction_list[p][5]) + \"%)\", fontsize=15, color= image_prediction_list[p][7])\n","                #jpegで保存\n","                plt.savefig(save_dir + \"/group\" + str(group_no) + \"-1.jpg\")\n","\n","                \n","                \n","                #２枚目以降のプロット\n","                additional_page = 1\n","\n","                while (i-14-(additional_page-1)*16) \u003e 1:\n","                    plt.figure(figsize=(23, 27))\n","                    for p in range(16):\n","                        actual_i = p+14+16*(additional_page-1)\n","                        if actual_i == i:\n","                            break\n","                        else:\n","                            plt.subplot(4, 4, p+1)\n","                            plt.imshow(image_prediction_list[actual_i][4])\n","                            plt.axis('off')\n","\n","                            # 画像の上に、教員のアノテーションラベルとAIの予測ラベルを表示\n","                            # アノテーションと予測ラベルが合致する場合、赤色で、間違っている場合は青色で表示する\n","                            # 日本語の濁点が分離してしまう問題にも対応\n","                            plt.title(\n","                                \"Annotated label:\" + image_prediction_list[actual_i][0] + \"\\nPredicted label: \" + image_prediction_list[actual_i][6]\n","                                + \" (\" + str(image_prediction_list[actual_i][5]) + \"%)\", fontsize=15, color= image_prediction_list[actual_i][7])\n","                        \n","                    #jpegで保存\n","                    plt.savefig(save_dir + \"/group\" + str(group_no) + \"-\" + str(additional_page + 1) + \".jpg\")\n","                    additional_page += 1\n","                \n","                \n","                # 点数の保存\n","                scores.append([group_no, Decimal(correct / i *100).quantize(Decimal('0.0'), rounding=ROUND_HALF_UP), total_sample_number])\n","            \n","            #推論画像が分類されていない場合    \n","            else:\n","                i = 0\n","                image_prediction_list = []\n","                image_files = os.listdir(test_data_dir)\n","                for m in range(len(image_files)):\n","                    patternStr = '.+\\.(jpg|jpeg|png|PNG)'\n","                    pattern = re.compile(patternStr)\n","                    result = pattern.match(image_files[m])\n","                    \n","                    if result:\n","                        image = Image.open(test_data_dir + \"/\" + image_files[m])\n","                        image_prediction_list.append([\"null\", image_files[m]])\n","                        prediction_result = image_prediction(image)\n","                        for n in range(3):\n","                            image_prediction_list[i].append(prediction_result[n])\n","                            \n","                        total_score = 0\n","                        predicted_scores = prediction_result[0][0]\n","                        for o in range(len(predicted_scores)):\n","                            if predicted_scores[o] \u003e 0:\n","                               total_score += predicted_scores[o]\n","                               predicted_percentage = max(predicted_scores) / total_score * 100 // 1\n","                        image_prediction_list[i].append(predicted_percentage) \n","                        predicted_label = normalize(\"NFC\", get_class_string_from_index(image_prediction_list[i][3]))\n","                        image_prediction_list[i].append(predicted_label)\n","                        \n","        #image_prediction_listは[\"null\"、画像ファイル名、prediction_score,predicted_index,\n","        #                       image_file, predicted_percentage, predicted_label]\n","                        i+=1\n","                \n","                x, y = next(valid_generator) \n","                # 予測結果を表示させるための図の作成  \n","                plt.figure(figsize=(23, 27))\n","                \n","                ##転移学習の結果(lossとaccuracy)をプロット\n","                plt.subplot(4, 4, 1)  # 図を4x4分割した時の1番目に配置するという意味（以下同じ）\n","                plt.ylabel(\"Loss (training and validation)\", fontsize=15)\n","                plt.xlabel(\"Training Steps\", fontsize=15)\n","                plt.ylim([0, 2])\n","                plt.plot(hist[\"loss\"], label=\"training_loss\")\n","                \n","                ##データ数が少なくvalidationできなかった時のエラー回避\n","                try:\n","                    plt.plot(hist[\"val_loss\"], label=\"valuation_loss\")\n","                except:\n","                    print(\"The number of image files were not enough to valuation\")\n","                \n","                plt.legend()\n","                plt.subplot(4, 4, 2)\n","                plt.ylabel(\"Accuracy (training and validation)\", fontsize=15)\n","                plt.xlabel(\"Training Steps\", fontsize=15)\n","                plt.ylim([0, 1])\n","                plt.plot(hist[\"accuracy\"], label=\"training_accuracy\")\n","                ##データ数が少なくvalidationできなかった時のエラー回避\n","                try:\n","                    plt.plot(hist[\"val_accuracy\"], label=\"valuation_accuracy\")\n","                except:\n","                    print(\"\")\n","                plt.legend()\n","                \n","                # 正答率と画像枚数をタイトルとして表示\n","                plt.suptitle(\n","                    \"班番号：\" + str(group_no) + \n","                    \"\\n訓練用画像数（トータル）：\" + str(total_sample_number) + \"\\n\" + sample_number_str,\n","                    fontsize=24)\n","               \n","                for p in range(14):\n","                    if p == i:\n","                        break\n","                    else:\n","                        plt.subplot(4, 4, p + 3)\n","                        plt.imshow(image_prediction_list[p][4])\n","                        plt.axis('off')\n","                        #　画像の下に画像名を表示\n","                        #plt.set_xlabel(image_prediction_list[p][1])\n","\n","                        # 画像の上に、AIの予測ラベルを表示\n","                        # 日本語の濁点が分離してしまう問題にも対応\n","                        plt.title(\n","                            image_prediction_list[p][1]\n","                            + \"\\nPredicted label: \" + image_prediction_list[p][6]\n","                            + \" (\" + str(image_prediction_list[p][5]) + \"%)\", fontsize=15)\n","                #jpegで保存\n","                plt.savefig(save_dir + \"/group\" + str(group_no) + \"-1.jpg\")\n","                \n","                #２枚目以降のプロット\n","                additional_page = 1\n","                \n","                while (i-14-(additional_page-1)*16) \u003e 1:\n","                    plt.figure(figsize=(23, 27))\n","                    for p in range(16):\n","                        actual_i = p+14+16*(additional_page-1)\n","                        if actual_i == i:\n","                            break\n","                        else:\n","                            plt.subplot(4, 4, p+1)\n","                            plt.imshow(image_prediction_list[actual_i][4])\n","                            plt.axis('off')\n","                            #　画像の下に画像名を表示\n","                            #plt.set_xlabel(image_prediction_list[p][1])\n","\n","                            # 画像の上に、AIの予測ラベルを表示\n","                            # 日本語の濁点が分離してしまう問題にも対応\n","                            plt.title(\n","                                image_prediction_list[actual_i][1]\n","                                + \"\\nPredicted label: \" + image_prediction_list[actual_i][6]\n","                               + \" (\" + str(image_prediction_list[actual_i][5]) + \"%)\", fontsize=15)\n","                        \n","                    #jpegで保存\n","                    plt.savefig(save_dir + \"/group\" + str(group_no) + \"-\" + str(additional_page + 1) + \".jpg\")\n","                    additional_page += 1\n","    \n","    except:\n","        print(\"There is no image in group_\" + str(group_no))\n","\n","if Test_images_are_clasified:\n","    sortsecond = lambda val: val[1]\n","    scores.sort(key=sortsecond, reverse=True)\n","\n","    for n in range(len(scores)):\n","        print(\"Group No.: \" + str(scores[n][0]) + \" Accuracy: \" + str(scores[n][1]) + \"% \" + str(scores[n][2]) + \" images\")\n","\n","\n","elapsed_time = time.time() - start_time\n","print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMQ/lg/eV+L4Ytq68IxBnZx","collapsed_sections":[],"name":"Histology_group_220208.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}